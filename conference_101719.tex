\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}   
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{A Transformer Based Pipeline for Software Requirements Classification\\
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{1\textsuperscript{st} Maheen Mashrur Hoque}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{Islamic University of Technology}\\
Gazipur, Bangladesh \\
email address or ORCID}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Arman Hossain Dipu Khan}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{Islamic University of Technology}\\
Gazipur, Bangladesh \\
email address or ORCID}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Ahsan Habib}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{Islamic University of Technology}\\
Gazipur, Bangladesh \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Ajwad Abrar}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{Islamic University of Technology}\\
Gazipur, Bangladesh \\
email address or ORCID}
\and
}

\maketitle

\begin{abstract}
The automation of the software development lifecycle (SDLC) is a key challenge in the field of software development. One of the main challenges in automation of the SDLC lies within the work of collecting, analyzing and establishing requirements, where the requirements collected from the stakeholders are often noisy, which can be difficult to organize. In order to facilitate the automation of requirement analysis, our study proposes two cost effective approaches, the first being leveraging the lightweight DistilBERT and RoBERTA models with a method called ``Ensemble Pooling'' to filter out relevant requirements, and the second one being a retrieval augmented generation (RAG) based classification leveraging GPT-4 and ChromaDB vector store to discriminate between functional and non-functional requirements. The experiments conducted by us showcased an accuracy of 78\% for the first approach and 86.67\% in the second approach.
\end{abstract}

\begin{IEEEkeywords}
Software Requirements, Software Development Lifecycle (SDLC), Classification, Natural Language Processing (NLP), Transformers, Retrieval Augmented Generation (RAG), Ensemble 
\end{IEEEkeywords}

\section{Introduction}
Software requirements can be thought of very high level description of what a software system is expected to do in order to solve a business requirements and are the reflection of the expectations of the stakeholders and clients \cite{pohl2016requirements}. Software requirements are typically divided into three categories \cite{sommerville2011software} -- Functional (Specify the purpose of the system), Non-Functional (Define the system's quality attributes such as performance), and Domain Requirements (Specific to the context of the application domain such as memory requirement). A requirement should have clarity, be consistent and have completeness \cite{wiegers2013software}. However, factors like communication gap, difference in perspective, and complexity of scope can make requirements vague and difficult to comprehend for the developer \cite{nuseibeh2000requirements}. Due to these factors, requirements from the stakeholders may often contain irrelevant information (which we are referring to as ``noise''), and it can be difficult to discern functional and non-functional requirements. This causes bottleneck in the SDLC as system architects spend much time organizing the requirements. The challenge of requirements organization can be classified as a natural language processing (NLP) problem. Hence, our research objective (RO) in this work is to deal with two critical steps:
\begin{itemize}
    \item \textbf{RO1:} Noise reduction via classifying relevant and irrelevant requirements.
    \item \textbf{RO2:} Improving requirement assessment via functional and non-Functional requirements.
\end{itemize}
In both objectives, we experimented with two different approach for classification, with the works of Ivanov et. al. \cite{ivanov2021regexppure_extracting_software_requirements} acting as baseline. The experiments, dataset and results are discussed in later sections.


\section{Literature Review}
\label{Literature Review}

This section provides a comprehensive descriptions of the previous works that were reviewed for this research. In order to avoid parochial view over the research objective, the reviews were not limited to only language model based approaches.

\subsection{Esoteric Approach}

The works of  Siahaan and Darnoto distinguishes irrelevant requirements using the MultiPhiLDA  method \cite{siahaan2022novel}. Their method works by distinguishing topicâ€“word distribution of actor words and action words, governed by polynomial probability functions, essentially making it a statistical distribution analysis. 

Another method by Alharbi et. al. leverages semantic embeddings to filter ambiguous requirements \cite{alharbi2022ambiguity}. The embedding were fine-tuned to the specific task, allowing it to capture context-specific nuances related to ambiguity.

Similarly, the works pf Malik et. al. leverages cosine similarity over sentence embeddings to classify conflicting requirements \cite{malik2022identifying}. Although, not directly related, this work provided us insight on how to levarage similarity scores. 

\subsection{Language Model Approach}

A language model based approach by Ivanov et. al. for extracting requirements from unstructured text uses BERT \cite{devlin2018bert} model fine-tuned with a manually annotated dataset from the PURE (Public Requirements) corpus \cite{ferrari2017pure}. They achieved an accuracy of 74\%, compared to two other baseline approaches -- fastText (open source natural language processing toolkit) with an accuracy of 60\%, and ELMo (a foundational text-embedding model) paired with SVM (Support Vector Machine classifier) with an accuracy of 59\%. Due to the similarity of objective, this work was considered as a baseline for us to compare against. 


\section{Dataset}
\label{Dataset}

\subsection{PURE Dataset}

For our work the, the PURE (Public Requirements) dataset \cite{ferrari2017pure}, created by Ferrari et. al., was the primary source of data for the experiments of RO1. This contains 79 software requirements document (SRS) that contains 34,286 sentences. However, the dataset does not provide any additional labelling for the requirements sentences to aid natural language processing tasks. Some of the previous works, notably \cite{ivanov2021regexppure_extracting_software_requirements} and \cite{siahaan2022novel} utilized this dataset in their works via labeling in various ways. 

A labeled subset of the PURE dataset, called the RegExpPURE Dataset by Ivanov et. al. \cite{ivanov2021regexppure_extracting_software_requirements} was used in our studies. This dataset has proper balancing in it's data, with 2474 not requirements and 2832 requirements in train, 467 not requirements and 1058 requirements in test and 255 not requirements and 650 requirements in validation set, making it a suitable training candidate.


\subsection{FR-NFR Dataset}

For the experiments of RO2, a custom dataset was made with SRS documents from 3 real projects conducted by the Ministry of ICT, The People's Republic of Bangladesh - A Training Database, an Enterprise Management System, and an AI Chatbot. The requirements were collected and labeled into FR (Functional Requirements) and NFR (Non-Functional Requirements) by three expert personnel from the software industry of Bangladesh - two experienced product managers and an experienced AI engineer. To handle labeling conflict, we revisited standard definitions of FR and NFR \cite{wiegers2013software}, and industry-recognized standards such as IEEE guidelines \cite{schmidt2000implementing} and had discussions until agreement was reached. 




% \section{Ease of Use}

% \subsection{Maintaining the Integrity of the Specifications}

% The IEEEtran class file is used to format your paper and style the text. All margins, 
% column widths, line spaces, and text fonts are prescribed; please do not 
% alter them. You may note peculiarities. For example, the head margin
% measures proportionately more than is customary. This measurement 
% and others are deliberate, using specifications that anticipate your paper 
% as one part of the entire proceedings, and not as an independent document. 
% Please do not revise any of the current designations.

% \section{Prepare Your Paper Before Styling}

% \subsection{Figures and Tables}
% \paragraph{Positioning Figures and Tables} Place figures and tables at the top and 
% bottom of columns. Avoid placing them in the middle of columns. Large 
% figures and tables may span across both columns. Figure captions should be 
% below the figures; table heads should appear above the tables. Insert 
% figures and tables after they are cited in the text. Use the abbreviation 
% ``Fig.~\ref{fig}'', even at the beginning of a sentence.

% \begin{table}[htbp]
% \caption{Table Type Styles}
% \begin{center}
% \begin{tabular}{|c|c|c|c|}
% \hline
% \textbf{Table}&\multicolumn{3}{|c|}{\textbf{Table Column Head}} \\
% \cline{2-4} 
% \textbf{Head} & \textbf{\textit{Table column subhead}}& \textbf{\textit{Subhead}}& \textbf{\textit{Subhead}} \\
% \hline
% copy& More table copy$^{\mathrm{a}}$& &  \\
% \hline
% \multicolumn{4}{l}{$^{\mathrm{a}}$Sample of a Table footnote.}
% \end{tabular}
% \label{tab1}
% \end{center}
% \end{table}

% \begin{figure}[htbp]
% \centerline{\includegraphics{fig1.png}}
% \caption{Example of a figure caption.}
% \label{fig}
% \end{figure}



\bibliographystyle{IEEEtran}
\bibliography{Bibliography}


\end{document}
